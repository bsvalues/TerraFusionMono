#!/usr/bin/env python3
"""
Simple PostgreSQL backup using psycopg2.

This script creates a backup of the database schema and data using psycopg2,
avoiding pg_dump compatibility issues.

Usage:
    python pg_backup_simple.py [--output-dir DIRECTORY]

Options:
    --output-dir DIR  Custom directory for backups (default: ./backups)
"""

import os
import sys
import logging
import argparse
import datetime
import psycopg2
from urllib.parse import urlparse

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

def create_directory(path):
    """Create a directory if it doesn't exist."""
    if not os.path.exists(path):
        try:
            os.makedirs(path)
            logger.info(f"Created directory: {path}")
            return True
        except Exception as e:
            logger.error(f"Failed to create directory {path}: {e}")
            return False
    return True

def get_connection_params():
    """
    Extract PostgreSQL connection parameters from environment variables.
    
    Returns:
        Dict with connection parameters or None if not available
    """
    db_url = os.environ.get('DATABASE_URL')
    if not db_url:
        logger.error("DATABASE_URL environment variable not set")
        return None
    
    # Extract parameters from connection string
    if db_url.startswith('postgresql://'):
        try:
            parsed = urlparse(db_url)
            return {
                'host': parsed.hostname,
                'port': parsed.port or 5432,
                'user': parsed.username,
                'password': parsed.password,
                'database': parsed.path.lstrip('/')
            }
        except Exception as e:
            logger.error(f"Failed to parse DATABASE_URL: {e}")
            return None
    else:
        # Use environment variables if set
        host = os.environ.get('PGHOST')
        port = os.environ.get('PGPORT', 5432)
        user = os.environ.get('PGUSER')
        password = os.environ.get('PGPASSWORD')
        database = os.environ.get('PGDATABASE')
        
        # Check if all required parameters are available
        if not all([host, user, password, database]):
            logger.error("Missing required PostgreSQL connection parameters")
            return None
            
        return {
            'host': host,
            'port': port,
            'user': user,
            'password': password,
            'database': database
        }

def backup_database(backup_dir=None):
    """
    Create a backup of the PostgreSQL database.
    
    Args:
        backup_dir: Directory to save the backup (default: ./backups)
        
    Returns:
        Tuple of (success, filepath)
    """
    # Use default backup directory if not specified
    backup_dir = backup_dir or os.path.join(os.getcwd(), 'backups')
    
    # Create the backup directory if it doesn't exist
    if not create_directory(backup_dir):
        return False, None
    
    # Get connection parameters
    params = get_connection_params()
    if not params:
        return False, None
    
    # Generate backup filename with timestamp
    timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    backup_filename = f"pg_backup_{timestamp}.sql"
    backup_filepath = os.path.join(backup_dir, backup_filename)
    
    logger.info(f"Creating backup of {params['database']} database...")
    
    try:
        # Connect to the database
        conn = psycopg2.connect(
            host=params['host'],
            port=params['port'],
            user=params['user'],
            password=params['password'],
            database=params['database']
        )
        conn.autocommit = True
        cursor = conn.cursor()
        
        # Get list of tables
        cursor.execute("""
            SELECT tablename 
            FROM pg_tables 
            WHERE schemaname = 'public'
            ORDER BY tablename
        """)
        tables = cursor.fetchall()
        
        if not tables:
            logger.warning("No tables found to backup.")
            return False, None
        
        logger.info(f"Found {len(tables)} tables to backup.")
        
        with open(backup_filepath, 'w') as f:
            # Write backup header
            f.write(f"-- Database Backup: {params['database']}\n")
            f.write(f"-- Date: {datetime.datetime.now().isoformat()}\n")
            f.write(f"-- Generated by: pg_backup_simple.py\n\n")
            
            # Get database schema (tables and constraints)
            logger.info("Exporting database schema...")
            
            # Export each table's schema and data
            for table_name_tuple in tables:
                table_name = table_name_tuple[0]
                logger.info(f"Processing table: {table_name}")
                
                # Write table schema
                f.write(f"\n-- Table structure for {table_name}\n")
                
                # Use information_schema to get column details
                cursor.execute(f"""
                    SELECT column_name, data_type, character_maximum_length, 
                           is_nullable, column_default
                    FROM information_schema.columns
                    WHERE table_name = '{table_name}'
                    ORDER BY ordinal_position;
                """)
                columns = cursor.fetchall()
                
                # Get primary key information
                cursor.execute(f"""
                    SELECT a.attname
                    FROM   pg_index i
                    JOIN   pg_attribute a ON a.attrelid = i.indrelid
                                         AND a.attnum = ANY(i.indkey)
                    WHERE  i.indrelid = '{table_name}'::regclass
                    AND    i.indisprimary;
                """)
                primary_keys = [pk[0] for pk in cursor.fetchall()]
                
                # Build CREATE TABLE statement
                f.write(f"DROP TABLE IF EXISTS {table_name} CASCADE;\n")
                f.write(f"CREATE TABLE {table_name} (\n")
                col_defs = []
                for col_info in columns:
                    col_name, data_type, max_length, is_nullable, default = col_info
                    
                    # Build column type with length if applicable
                    if max_length is not None and data_type in ('character varying', 'character'):
                        col_type = f"{data_type}({max_length})"
                    else:
                        col_type = data_type
                        
                    # Add nullability
                    nullable = "NULL" if is_nullable == "YES" else "NOT NULL"
                    
                    # Add default if present
                    default_clause = f" DEFAULT {default}" if default else ""
                    
                    col_defs.append(f"    {col_name} {col_type} {nullable}{default_clause}")
                
                # Add primary key constraint if found
                if primary_keys:
                    col_defs.append(f"    PRIMARY KEY ({', '.join(primary_keys)})")
                    
                f.write(",\n".join(col_defs))
                f.write("\n);\n")
                
                # Get table data
                cursor.execute(f"SELECT * FROM {table_name};")
                rows = cursor.fetchall()
                
                if rows:
                    # Get column names
                    colnames = [desc[0] for desc in cursor.description]
                    
                    # Write INSERT statements
                    f.write(f"\n-- Data for {table_name}\n")
                    for row in rows:
                        values = []
                        for val in row:
                            if val is None:
                                values.append("NULL")
                            elif isinstance(val, str):
                                # Escape single quotes
                                escaped_val = val.replace("'", "''")
                                values.append(f"'{escaped_val}'")
                            elif isinstance(val, datetime.datetime):
                                values.append(f"'{val}'")
                            elif isinstance(val, (bool, int, float)):
                                values.append(str(val))
                            else:
                                values.append(f"'{val}'")
                        
                        f.write(f"INSERT INTO {table_name} ({', '.join(colnames)}) VALUES ({', '.join(values)});\n")
            
            # Export foreign key constraints
            cursor.execute("""
                SELECT
                    tc.constraint_name,
                    tc.table_name as table_name,
                    kcu.column_name as column_name,
                    ccu.table_name AS foreign_table_name,
                    ccu.column_name AS foreign_column_name,
                    rc.update_rule,
                    rc.delete_rule
                FROM
                    information_schema.table_constraints tc
                JOIN information_schema.key_column_usage kcu
                    ON tc.constraint_name = kcu.constraint_name
                    AND tc.table_schema = kcu.table_schema
                JOIN information_schema.constraint_column_usage ccu
                    ON ccu.constraint_name = tc.constraint_name
                    AND ccu.table_schema = tc.table_schema
                JOIN information_schema.referential_constraints rc
                    ON tc.constraint_name = rc.constraint_name
                WHERE
                    tc.constraint_type = 'FOREIGN KEY'
                    AND tc.table_schema = 'public'
                ORDER BY
                    tc.table_name, tc.constraint_name;
            """)
            
            foreign_keys = cursor.fetchall()
            
            if foreign_keys:
                f.write("\n-- Foreign Key Constraints\n")
                for fk in foreign_keys:
                    constraint_name, table_name, column_name, foreign_table, foreign_column, update_rule, delete_rule = fk
                    
                    f.write(f"ALTER TABLE {table_name} ADD CONSTRAINT {constraint_name} ")
                    f.write(f"FOREIGN KEY ({column_name}) REFERENCES {foreign_table}({foreign_column}) ")
                    f.write(f"ON UPDATE {update_rule} ON DELETE {delete_rule};\n")
            
            # Export sequences
            cursor.execute("""
                SELECT sequence_name
                FROM information_schema.sequences
                WHERE sequence_schema = 'public';
            """)
            sequences = cursor.fetchall()
            
            if sequences:
                f.write("\n-- Sequences\n")
                for seq_name_tuple in sequences:
                    seq_name = seq_name_tuple[0]
                    cursor.execute(f"SELECT last_value FROM {seq_name};")
                    last_value = cursor.fetchone()[0]
                    f.write(f"SELECT setval('{seq_name}', {last_value}, true);\n")
        
        conn.close()
        
        # Verify the backup was successful
        if os.path.exists(backup_filepath) and os.path.getsize(backup_filepath) > 0:
            backup_size = os.path.getsize(backup_filepath) / (1024 * 1024)  # Convert to MB
            logger.info(f"Backup created successfully: {backup_filepath} ({backup_size:.2f} MB)")
            return True, backup_filepath
        else:
            logger.error("Backup file is empty or does not exist")
            return False, None
            
    except Exception as e:
        logger.error(f"Error during backup: {e}")
        return False, None

def main():
    """Run the database backup."""
    parser = argparse.ArgumentParser(
        description="Simple PostgreSQL backup using psycopg2",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog=__doc__
    )
    
    parser.add_argument('--output-dir', 
                       help='Custom directory for backups (default: ./backups)')
    
    args = parser.parse_args()
    
    # Perform the backup
    success, backup_file = backup_database(args.output_dir)
    
    if success:
        logger.info("Database backup completed successfully")
        sys.exit(0)
    else:
        logger.error("Database backup failed")
        sys.exit(1)

if __name__ == '__main__':
    main()